{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Start the dataset by adding synthetic noise to the image dataset available**"
      ],
      "metadata": {
        "id": "MkNoquAx4qOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "input_folder = '/content/drive/MyDrive/Dataset_noisy/Kodak24'\n",
        "output_folder = '/content/drive/MyDrive/Dataset_noisy/noisy_kodak24'\n",
        "\n",
        "# Ensure output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Function to add Gaussian noise\n",
        "def add_gaussian_noise(image, std_dev):\n",
        "    noise = np.random.normal(0, std_dev, image.shape).astype(np.float32)\n",
        "    noisy_image = image.astype(np.float32) + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
        "    return noisy_image\n",
        "\n",
        "# Noise levels\n",
        "noise_levels = [10, 20, 30, 40]\n",
        "\n",
        "# Process images\n",
        "for noise_level in noise_levels:\n",
        "    noise_output_folder = os.path.join(output_folder, f'noise_{noise_level}')\n",
        "    os.makedirs(noise_output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.lower().endswith(('jpg', 'png','bmp')):\n",
        "            file_path = os.path.join(input_folder, filename)\n",
        "\n",
        "            # Read image\n",
        "            image = cv2.imread(file_path)\n",
        "            if image is None:\n",
        "                print(f\"Skipping file {filename} (not an image)\")\n",
        "                continue\n",
        "\n",
        "            # Add Gaussian noise\n",
        "            noisy_image = add_gaussian_noise(image, noise_level)\n",
        "\n",
        "            # Save noisy image\n",
        "            noisy_image_path = os.path.join(noise_output_folder, filename)\n",
        "            cv2.imwrite(noisy_image_path, noisy_image)\n",
        "            print(f\"Saved noisy image: {noisy_image_path}\")\n",
        "\n",
        "print(\"All noisy images have been created and saved.\")\n"
      ],
      "metadata": {
        "id": "ICf14RkB5GOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADD Some libararies to the model"
      ],
      "metadata": {
        "id": "G1t4vlIS5SwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchsummary\n"
      ],
      "metadata": {
        "id": "N7A0EjXQ5c8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pillow\n"
      ],
      "metadata": {
        "id": "av5LQeTO6hx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# code to extract parameters."
      ],
      "metadata": {
        "id": "tv6pFgGq5kcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchsummary\n",
        "\n",
        "# Define CBAM attention module\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels // reduction, kernel_size=1, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels // reduction, channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.Conv2d(2, 1, kernel_size=7, stride=1, padding=3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Channel Attention\n",
        "        channel_att = self.channel_attention(x)\n",
        "        x = x * channel_att\n",
        "\n",
        "        # Spatial Attention\n",
        "        avg_pool = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_pool, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        spatial_input = torch.cat([avg_pool, max_pool], dim=1)\n",
        "        spatial_att = self.spatial_attention(spatial_input)\n",
        "        x = x * spatial_att\n",
        "\n",
        "        return x\n",
        "\n",
        "# Define Attentive Dilated Convolution Block\n",
        "class AttentiveDilatedConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dilation_rates=(1, 2, 3)):\n",
        "        super(AttentiveDilatedConvBlock, self).__init__()\n",
        "        self.dilated_convs = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, dilation=dilation_rates[0], padding=dilation_rates[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=dilation_rates[1], padding=dilation_rates[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=dilation_rates[2], padding=dilation_rates[2]),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "        self.cbam = CBAM(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dilated_convs(x)\n",
        "        x = self.cbam(x)\n",
        "        return x\n",
        "\n",
        "# Define the full model\n",
        "class DenoisingModel(nn.Module):\n",
        "    def __init__(self, num_blocks=15, in_channels=3, out_channels=3, block_channels=64):\n",
        "        super(DenoisingModel, self).__init__()\n",
        "        self.initial_conv = nn.Conv2d(in_channels, block_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[AttentiveDilatedConvBlock(block_channels, block_channels) for _ in range(num_blocks)]\n",
        "        )\n",
        "        self.final_conv = nn.Conv2d(block_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.final_conv(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate and summarize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = DenoisingModel().to(device)\n",
        "\n",
        "# Print model summary\n",
        "torchsummary.summary(model, input_size=(3, 128, 128))  # Assuming input image size is 128x128\n"
      ],
      "metadata": {
        "id": "4ujPWom45eJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# code to train the model"
      ],
      "metadata": {
        "id": "2Ehyb-4y6swa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# ========== ADC BLOCK ==========\n",
        "class ADCBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ADCBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.skip_connection = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.skip_connection(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        return x + residual\n",
        "\n",
        "# ========== MODEL ==========\n",
        "class DenoisingModel(nn.Module):\n",
        "    def __init__(self, num_blocks):\n",
        "        super(DenoisingModel, self).__init__()\n",
        "        blocks = [ADCBlock(3, 64)]\n",
        "        blocks += [ADCBlock(64, 64) for _ in range(num_blocks - 1)]\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# ========== DATASET ==========\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, noisy_dir, clean_dir, transform=None):\n",
        "        self.noisy_images = sorted([os.path.join(noisy_dir, f) for f in os.listdir(noisy_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.clean_images = sorted([os.path.join(clean_dir, f) for f in os.listdir(clean_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.transform = transform if transform else transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.noisy_images), len(self.clean_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy_image = Image.open(self.noisy_images[idx]).convert('RGB')\n",
        "        clean_image = Image.open(self.clean_images[idx]).convert('RGB')\n",
        "        return self.transform(noisy_image), self.transform(clean_image)\n",
        "\n",
        "# ========== TRAIN FUNCTION ==========\n",
        "def train_model(model, train_loader, optimizer, criterion, num_epochs, checkpoint_path, device):\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "    print(\"✅ Starting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\" Starting epoch {epoch+1}\")\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (noisy_images, clean_images) in enumerate(train_loader):\n",
        "            noisy_images = noisy_images.to(device)\n",
        "            clean_images = clean_images.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(noisy_images)\n",
        "            loss = criterion(outputs, clean_images)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if batch_idx % 5 == 0:\n",
        "                print(f\"   Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\" Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }\n",
        "            filename = os.path.join(checkpoint_path, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "            torch.save(checkpoint, filename)\n",
        "            print(f\"💾 Checkpoint saved at {filename}\")\n",
        "\n",
        "# ========== MAIN SETUP ==========\n",
        "# Paths\n",
        "noisy_dir = \"/content/drive/MyDrive/Dataset_noisy/noisy_bsd68/noise_10\"\n",
        "clean_dir = \"/content/drive/MyDrive/Datasets/BSD68\"\n",
        "checkpoint_path = \"/content/drive/MyDrive/Dataset_noisy/validation/training1\"\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\" Using device: {device}\")\n",
        "\n",
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Dataset and Dataloader\n",
        "dataset = ImageDataset(noisy_dir, clean_dir, transform=transform)\n",
        "print(f\" Number of training images: {len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Model, optimizer, and loss\n",
        "model = DenoisingModel(num_blocks=15).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Train\n",
        "train_model(model, train_loader, optimizer, criterion, num_epochs=1000, checkpoint_path=checkpoint_path, device=device)\n"
      ],
      "metadata": {
        "id": "qGdcTu306u1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model from the previouus saved checkpoint and pass the model forward"
      ],
      "metadata": {
        "id": "RLm-ox_M62yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# ========== ADC BLOCK ==========\n",
        "class ADCBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ADCBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.skip_connection = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.skip_connection(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        return x + residual\n",
        "\n",
        "# ========== MODEL ==========\n",
        "class DenoisingModel(nn.Module):\n",
        "    def __init__(self, num_blocks):\n",
        "        super(DenoisingModel, self).__init__()\n",
        "        blocks = [ADCBlock(3, 64)]\n",
        "        blocks += [ADCBlock(64, 64) for _ in range(num_blocks - 1)]\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# ========== DATASET ==========\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, noisy_dir, clean_dir, transform=None):\n",
        "        self.noisy_images = sorted([os.path.join(noisy_dir, f) for f in os.listdir(noisy_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.clean_images = sorted([os.path.join(clean_dir, f) for f in os.listdir(clean_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.transform = transform if transform else transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.noisy_images), len(self.clean_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy_image = Image.open(self.noisy_images[idx]).convert('RGB')\n",
        "        clean_image = Image.open(self.clean_images[idx]).convert('RGB')\n",
        "        return self.transform(noisy_image), self.transform(clean_image)\n",
        "\n",
        "# ========== TRAIN FUNCTION ==========\n",
        "def train_model(model, train_loader, optimizer, criterion, num_epochs, checkpoint_path, device, resume_checkpoint=None):\n",
        "    if resume_checkpoint and os.path.exists(resume_checkpoint):\n",
        "        print(f\"🔁 Loading checkpoint from {resume_checkpoint}\")\n",
        "        checkpoint = torch.load(resume_checkpoint, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(\"✅ Weights and optimizer state loaded. Starting training fresh from epoch 1.\")\n",
        "\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"🚀 Epoch {epoch}/{num_epochs}\")\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (noisy_images, clean_images) in enumerate(train_loader):\n",
        "            noisy_images = noisy_images.to(device)\n",
        "            clean_images = clean_images.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(noisy_images)\n",
        "            loss = criterion(outputs, clean_images)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if batch_idx % 5 == 0:\n",
        "                print(f\"   Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"📉 Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if epoch % 10 == 0:\n",
        "            save_path = os.path.join(checkpoint_path, f\"checkpoint_epoch_{epoch}.pth\")\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss\n",
        "            }, save_path)\n",
        "            print(f\"💾 Checkpoint saved at: {save_path}\")\n",
        "\n",
        "# ========== MAIN SETUP ==========\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    noisy_dir = \"/content/drive/MyDrive/Dataset_noisy/noisy_bsd68/noise_20\"\n",
        "    clean_dir = \"/content/drive/MyDrive/Datasets/BSD68\"\n",
        "    checkpoint_path = \"/content/drive/MyDrive/Dataset_noisy/validation/training2\"\n",
        "    resume_checkpoint = os.path.join(checkpoint_path, \"/content/drive/MyDrive/Dataset_noisy/validation/training1/checkpoint_epoch_1000.pth\")  # last checkpoint\n",
        "\n",
        "    # Device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Data\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    dataset = ImageDataset(noisy_dir, clean_dir, transform=transform)\n",
        "    train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "    print(f\"Total training images: {len(dataset)}\")\n",
        "\n",
        "    # Model\n",
        "    model = DenoisingModel(num_blocks=15).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Train for a new 1000 epochs (starting from epoch 1, resuming weights)\n",
        "    train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        num_epochs= 1000,\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        device=device,\n",
        "        resume_checkpoint=resume_checkpoint\n",
        "    )\n"
      ],
      "metadata": {
        "id": "AD-U23D87XNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same code for training all levels of noise."
      ],
      "metadata": {
        "id": "NiAl9u4479UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# ========== ADC BLOCK ==========\n",
        "class ADCBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ADCBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.skip_connection = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.skip_connection(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        return x + residual\n",
        "\n",
        "# ========== MODEL ==========\n",
        "class DenoisingModel(nn.Module):\n",
        "    def __init__(self, num_blocks):\n",
        "        super(DenoisingModel, self).__init__()\n",
        "        blocks = [ADCBlock(3, 64)]\n",
        "        blocks += [ADCBlock(64, 64) for _ in range(num_blocks - 1)]\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# ========== DATASET ==========\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, noisy_dir, clean_dir, transform=None):\n",
        "        self.noisy_images = sorted([os.path.join(noisy_dir, f) for f in os.listdir(noisy_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.clean_images = sorted([os.path.join(clean_dir, f) for f in os.listdir(clean_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.transform = transform if transform else transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.noisy_images), len(self.clean_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy_image = Image.open(self.noisy_images[idx]).convert('RGB')\n",
        "        clean_image = Image.open(self.clean_images[idx]).convert('RGB')\n",
        "        return self.transform(noisy_image), self.transform(clean_image)\n",
        "\n",
        "# ========== TRAIN FUNCTION ==========\n",
        "def train_model(model, train_loader, optimizer, criterion, num_epochs, checkpoint_path, device, resume_checkpoint=None):\n",
        "    if resume_checkpoint and os.path.exists(resume_checkpoint):\n",
        "        print(f\"🔁 Loading checkpoint from {resume_checkpoint}\")\n",
        "        checkpoint = torch.load(resume_checkpoint, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(\"✅ Weights and optimizer state loaded. Starting training fresh from epoch 1.\")\n",
        "\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"🚀 Epoch {epoch}/{num_epochs}\")\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (noisy_images, clean_images) in enumerate(train_loader):\n",
        "            noisy_images = noisy_images.to(device)\n",
        "            clean_images = clean_images.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(noisy_images)\n",
        "            loss = criterion(outputs, clean_images)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if batch_idx % 5 == 0:\n",
        "                print(f\"   Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"📉 Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if epoch % 10 == 0:\n",
        "            save_path = os.path.join(checkpoint_path, f\"checkpoint_epoch_{epoch}.pth\")\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss\n",
        "            }, save_path)\n",
        "            print(f\"💾 Checkpoint saved at: {save_path}\")\n",
        "\n",
        "# ========== MAIN SETUP ==========\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    noisy_dir = \"/content/drive/MyDrive/Dataset_noisy/noisy_bsd68/noise_30\"\n",
        "    clean_dir = \"/content/drive/MyDrive/Datasets/BSD68\"\n",
        "    checkpoint_path = \"/content/drive/MyDrive/Dataset_noisy/validation/training3\"\n",
        "    resume_checkpoint = os.path.join(checkpoint_path, \"/content/drive/MyDrive/Dataset_noisy/validation/training2/checkpoint_epoch_1000.pth\")  # last checkpoint\n",
        "\n",
        "    # Device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Data\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    dataset = ImageDataset(noisy_dir, clean_dir, transform=transform)\n",
        "    train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "    print(f\"Total training images: {len(dataset)}\")\n",
        "\n",
        "    # Model\n",
        "    model = DenoisingModel(num_blocks=15).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Train for a new 1000 epochs (starting from epoch 1, resuming weights)\n",
        "    train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        num_epochs=1000,\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        device=device,\n",
        "        resume_checkpoint=resume_checkpoint\n",
        "    )\n"
      ],
      "metadata": {
        "id": "jTn6qiln8CAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "Mr4FMxDa8ipg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load your trained model\n",
        "def load_model(checkpoint_path, model, device):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"✅ Model loaded from {checkpoint_path}\")\n",
        "    return model\n",
        "\n",
        "# Dataset for Testing\n",
        "class TestImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, noisy_dir, clean_dir, transform=None):\n",
        "        self.noisy_images = sorted([os.path.join(noisy_dir, f) for f in os.listdir(noisy_dir) if f.endswith(('.png', '.jpg', '.jpeg','.bmp'))])\n",
        "        self.clean_images = sorted([os.path.join(clean_dir, f) for f in os.listdir(clean_dir) if f.endswith(('.png', '.jpg', '.jpeg','.bmp'))])\n",
        "        self.transform = transform if transform else transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy = Image.open(self.noisy_images[idx]).convert('RGB')\n",
        "        clean = Image.open(self.clean_images[idx]).convert('RGB')\n",
        "        return self.transform(noisy), self.transform(clean)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    psnr_total, ssim_total = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for noisy_imgs, clean_imgs in test_loader:\n",
        "            noisy_imgs = noisy_imgs.to(device)\n",
        "            clean_imgs = clean_imgs.to(device)\n",
        "\n",
        "            outputs = model(noisy_imgs)\n",
        "\n",
        "            for i in range(outputs.size(0)):\n",
        "                pred = outputs[i].cpu().numpy().transpose(1, 2, 0)\n",
        "                target = clean_imgs[i].cpu().numpy().transpose(1, 2, 0)\n",
        "\n",
        "                pred = np.clip(pred, 0, 1)\n",
        "                target = np.clip(target, 0, 1)\n",
        "\n",
        "                psnr_val = psnr(target, pred, data_range=1.0)\n",
        "                ssim_val = ssim(target, pred, data_range=1.0, channel_axis=2, win_size=7)\n",
        "\n",
        "\n",
        "\n",
        "                psnr_total += psnr_val\n",
        "                ssim_total += ssim_val\n",
        "                count += 1\n",
        "\n",
        "    avg_psnr = psnr_total / count\n",
        "    avg_ssim = ssim_total / count\n",
        "    print(f\"📈 Average PSNR: {avg_psnr:.4f}, Average SSIM: {avg_ssim:.4f}\")\n",
        "    return avg_psnr, avg_ssim\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    noisy_test_dir = \"/content/drive/MyDrive/Dataset_noisy/noisy_classic/noise_20\"\n",
        "    clean_test_dir = \"/content/drive/MyDrive/Dataset_noisy/classic5\"\n",
        "    checkpoint_path = \"/content/drive/MyDrive/Dataset_noisy/validation/training cbsd4/checkpoint_epoch_1000.pth\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Define transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    test_dataset = TestImageDataset(noisy_test_dir, clean_test_dir, transform=transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Load model\n",
        "    model = DenoisingModel(num_blocks=15)\n",
        "    model = load_model(checkpoint_path, model, device)\n",
        "\n",
        "    # Evaluate\n",
        "    evaluate_model(model, test_loader, device)\n"
      ],
      "metadata": {
        "id": "fDNEbnUF8lD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization of the model output"
      ],
      "metadata": {
        "id": "sw899Tme9C7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define your model architecture here (replace this with your actual model)\n",
        "\n",
        "class ADCBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ADCBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.skip_connection = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.skip_connection(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        return x + residual\n",
        "\n",
        "# ========== MODEL ==========\n",
        "class DenoisingModel(nn.Module):\n",
        "    def __init__(self, num_blocks):\n",
        "        super(DenoisingModel, self).__init__()\n",
        "        blocks = [ADCBlock(3, 64)]\n",
        "        blocks += [ADCBlock(64, 64) for _ in range(num_blocks - 1)]\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# Load trained model\n",
        "def load_model(checkpoint_path, model, device):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"✅ Model loaded from {checkpoint_path}\")\n",
        "    return model\n",
        "\n",
        "# Dataset for Testing\n",
        "class TestImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, noisy_dir, clean_dir, transform=None):\n",
        "        self.noisy_images = sorted([os.path.join(noisy_dir, f) for f in os.listdir(noisy_dir) if f.endswith(('.png', '.jpg', '.jpeg','.bmp'))])\n",
        "        self.clean_images = sorted([os.path.join(clean_dir, f) for f in os.listdir(clean_dir) if f.endswith(('.png', '.jpg', '.jpeg','.bmp'))])\n",
        "        self.transform = transform if transform else transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy = Image.open(self.noisy_images[idx]).convert('RGB')\n",
        "        clean = Image.open(self.clean_images[idx]).convert('RGB')\n",
        "        return self.transform(noisy), self.transform(clean)\n",
        "\n",
        "# Evaluation Function with image display and saving\n",
        "def evaluate_model(model, test_loader, device, show_images=True, save_output=False, output_dir=\"outputs\"):\n",
        "    if save_output and not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    psnr_total, ssim_total = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (noisy_imgs, clean_imgs) in enumerate(test_loader):\n",
        "            noisy_imgs = noisy_imgs.to(device)\n",
        "            clean_imgs = clean_imgs.to(device)\n",
        "\n",
        "            outputs = model(noisy_imgs)\n",
        "\n",
        "            for i in range(outputs.size(0)):\n",
        "                pred = outputs[i].cpu().numpy().transpose(1, 2, 0)\n",
        "                target = clean_imgs[i].cpu().numpy().transpose(1, 2, 0)\n",
        "                noisy = noisy_imgs[i].cpu().numpy().transpose(1, 2, 0)\n",
        "\n",
        "                pred = np.clip(pred, 0, 1)\n",
        "                target = np.clip(target, 0, 1)\n",
        "                noisy = np.clip(noisy, 0, 1)\n",
        "\n",
        "                psnr_val = psnr(target, pred, data_range=1.0)\n",
        "                ssim_val = ssim(target, pred, data_range=1.0, channel_axis=2, win_size=7)\n",
        "\n",
        "                psnr_total += psnr_val\n",
        "                ssim_total += ssim_val\n",
        "                count += 1\n",
        "\n",
        "                print(f\"Image {idx + 1}: PSNR = {psnr_val:.4f}, SSIM = {ssim_val:.4f}\")\n",
        "\n",
        "                if show_images or save_output:\n",
        "                    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "                    axs[0].imshow(noisy)\n",
        "                    axs[0].set_title(\"Noisy Input\")\n",
        "                    axs[0].axis(\"off\")\n",
        "                    axs[1].imshow(pred)\n",
        "                    axs[1].set_title(\"Denoised Output\")\n",
        "                    axs[1].axis(\"off\")\n",
        "                    axs[2].imshow(target)\n",
        "                    axs[2].set_title(\"Ground Truth\")\n",
        "                    axs[2].axis(\"off\")\n",
        "\n",
        "                    plt.suptitle(f\"PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}\")\n",
        "\n",
        "                    if save_output:\n",
        "                        plt.savefig(os.path.join(output_dir, f\"output_{idx+1}.png\"))\n",
        "                    if show_images:\n",
        "                        plt.show()\n",
        "                    plt.close()\n",
        "\n",
        "    avg_psnr = psnr_total / count\n",
        "    avg_ssim = ssim_total / count\n",
        "    print(f\"\\n📈 Average PSNR: {avg_psnr:.4f}, Average SSIM: {avg_ssim:.4f}\")\n",
        "    return avg_psnr, avg_ssim\n",
        "\n",
        "\n",
        "# Main Entry Point\n",
        "if __name__ == \"__main__\":\n",
        "    noisy_test_dir = \"/content/drive/MyDrive/Dataset_noisy/noisy_kodak24/noise_30\"\n",
        "    clean_test_dir = \"/content/drive/MyDrive/Dataset_noisy/Kodak24\"\n",
        "    checkpoint_path = \"/content/drive/MyDrive/Dataset_noisy/validation/training cbsd4/checkpoint_epoch_50.pth\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    test_dataset = TestImageDataset(noisy_test_dir, clean_test_dir, transform=transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    model = DenoisingModel(num_blocks=15)\n",
        "    model = load_model(checkpoint_path, model, device)\n",
        "\n",
        "    # Run evaluation with display\n",
        "    evaluate_model(model, test_loader, device, show_images=True, save_output=False)\n"
      ],
      "metadata": {
        "id": "YLtIr6j09LQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}